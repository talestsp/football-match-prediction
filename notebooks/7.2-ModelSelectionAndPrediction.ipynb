{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8edfa13",
   "metadata": {},
   "source": [
    "# Model Selection And Prediction\n",
    "Notebook to experiment different model configurations and store results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5969a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tales.pimentel/ds/kaggle/football-match-prediction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from working_dir import set_wd\n",
    "set_wd()\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48bcbd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.config('spark.ui.showConsoleProgress', 'false') \\\n",
    "                            .config(\"spark.sql.debug.maxToStringFields\", 500) \\\n",
    "                            .config(\"spark.sql.debug.autoBroadcastJoinThreshold\", -1) \\\n",
    "                            .config(\"spark.driver.memory\", \"10g\") \\\n",
    "                            .appName(\"ModelSelectionAndPrediction\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82d4c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.dao import dao_processed, dao_ml\n",
    "from src.utils import dflib, stats, pretties\n",
    "from src.ml.transformers import DropNaTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b287e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretties.max_data_frame_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac7ccc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_result_df(result):\n",
    "    result_df = pd.DataFrame(result[\"overfitting_analysis_df\"])\n",
    "    result_df[\"params\"] = result_df[list(result[\"clf_params\"].keys())].apply(lambda row : row.to_dict(), axis=1)\n",
    "    result_df[\"undersampling\"] = \"UndersamplingTransformer\" in result[\"pipeline_train_stages\"]\n",
    "    result_df[\"features\"] = str(result[\"feature_importances\"][\"importance\"].keys())\n",
    "    result_df[\"clf_name\"] = result[\"clf_name\"]\n",
    "    result_df[\"features\"] = str(list(result[\"feature_importances\"][\"importance\"].keys()))\n",
    "\n",
    "    return result_df[[\"clf_name\", \"undersampling\", \"log_loss_cv\", \"log_loss_train\", \"params\", \"features\"]].sort_values(\"log_loss_cv\")\n",
    "\n",
    "def get_top_configs(results, n=3):\n",
    "    return results.sort_values(\"log_loss_cv\").head(n)\n",
    "\n",
    "def remove_cols(cols, cols_to_remove):\n",
    "    for col_to_remove in cols_to_remove:\n",
    "        if col_to_remove in cols:\n",
    "            cols.remove(col_to_remove)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd6612c",
   "metadata": {},
   "source": [
    "# Loading Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e08f5207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_modeling</th>\n",
       "      <th>datetime</th>\n",
       "      <th>clf_name</th>\n",
       "      <th>undersampling</th>\n",
       "      <th>n_features</th>\n",
       "      <th>best_score_cv_train</th>\n",
       "      <th>best_score_cv</th>\n",
       "      <th>id_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a26f990a-12e8-4a8d-9e2e-74e4969f6508</td>\n",
       "      <td>2022-05-26 19:02:06</td>\n",
       "      <td>RandomForestClassificationModel</td>\n",
       "      <td>no</td>\n",
       "      <td>8</td>\n",
       "      <td>0.981899</td>\n",
       "      <td>1.012797</td>\n",
       "      <td>b2beffb2-fb6d-4cb4-8869-82b859c2dd3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d6e238c1-c6a8-41be-ac18-3cad3f47a420</td>\n",
       "      <td>2022-05-26 16:44:32</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>no</td>\n",
       "      <td>8</td>\n",
       "      <td>0.996144</td>\n",
       "      <td>1.010365</td>\n",
       "      <td>b2beffb2-fb6d-4cb4-8869-82b859c2dd3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6d671cab-ea98-4471-8455-0a8092241123</td>\n",
       "      <td>2022-05-26 15:52:32</td>\n",
       "      <td>RandomForestClassificationModel</td>\n",
       "      <td>no</td>\n",
       "      <td>8</td>\n",
       "      <td>0.982310</td>\n",
       "      <td>1.012607</td>\n",
       "      <td>b2beffb2-fb6d-4cb4-8869-82b859c2dd3b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id_modeling             datetime  \\\n",
       "2  a26f990a-12e8-4a8d-9e2e-74e4969f6508  2022-05-26 19:02:06   \n",
       "0  d6e238c1-c6a8-41be-ac18-3cad3f47a420  2022-05-26 16:44:32   \n",
       "1  6d671cab-ea98-4471-8455-0a8092241123  2022-05-26 15:52:32   \n",
       "\n",
       "                          clf_name undersampling  n_features  \\\n",
       "2  RandomForestClassificationModel            no           8   \n",
       "0                    XGBClassifier            no           8   \n",
       "1  RandomForestClassificationModel            no           8   \n",
       "\n",
       "   best_score_cv_train  best_score_cv                               id_data  \n",
       "2             0.981899       1.012797  b2beffb2-fb6d-4cb4-8869-82b859c2dd3b  \n",
       "0             0.996144       1.010365  b2beffb2-fb6d-4cb4-8869-82b859c2dd3b  \n",
       "1             0.982310       1.012607  b2beffb2-fb6d-4cb4-8869-82b859c2dd3b  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = dao_ml.load_all_modeling()\n",
    "print(len(all_results))\n",
    "\n",
    "all_results_df = pd.DataFrame(all_results)\n",
    "all_results_df[\"undersampling\"] = all_results_df[\"pipeline_train_stages\"].apply(lambda ppl : \"UndersamplingTransformer\" in ppl)\n",
    "\n",
    "all_results_df[\"undersampling\"] = all_results_df[\"undersampling\"].replace({True: \"balanced\", False: \"no\"})\n",
    "\n",
    "all_results_df[\"features\"] = all_results_df[\"feature_importances\"].apply(lambda fi : list(fi[\"importance\"].keys()))\n",
    "all_results_df[\"n_features\"] = all_results_df[\"features\"].apply(len)\n",
    "all_results_df[[\"id_modeling\", \"datetime\", \"clf_name\", \"undersampling\", \"n_features\",\n",
    "                 \"best_score_cv_train\", \"best_score_cv\", \"id_data\"]].sort_values(\"datetime\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a31bdbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_modeling_xgb_u = \"15a43545-665e-44b8-91ef-d21816c90c4e\"\n",
    "id_modeling_xgb = \"3118f21c-2508-4dfd-8a49-890f6d09bd4f\"\n",
    "id_modeling_rf_u = \"6846618f-8912-4f18-b8b7-ffb9fff01fc2\"\n",
    "id_modeling_rf = \"31949b43-998b-4669-90de-08ec5f75d64f\"\n",
    "\n",
    "results_xgb_u = dao_ml.load_modeling(id_modeling_xgb_u)\n",
    "results_xgb = dao_ml.load_modeling(id_modeling_xgb)\n",
    "results_rf_u = dao_ml.load_modeling(id_modeling_rf_u)\n",
    "results_rf = dao_ml.load_modeling(id_modeling_rf)\n",
    "\n",
    "results_xgb_u = build_result_df(results_xgb_u).sort_values(\"log_loss_cv\").head(3)\n",
    "results_xgb = build_result_df(results_xgb).sort_values(\"log_loss_cv\").head(3)\n",
    "results_rf_u = build_result_df(results_rf_u).sort_values(\"log_loss_cv\").head(3)\n",
    "results_rf = build_result_df(results_rf).sort_values(\"log_loss_cv\").head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2aa38",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7874f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbd64bc0-9cf2-44ad-a5c5-edcce0393bf4\n"
     ]
    }
   ],
   "source": [
    "id_data_build = dao_processed.most_recent_data_build_id()\n",
    "id_data_build = \"dbd64bc0-9cf2-44ad-a5c5-edcce0393bf4\"\n",
    "print(id_data_build)#\"dbd64bc0-9cf2-44ad-a5c5-edcce0393bf4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4152d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_data = dao_ml.load_feature_selection(id_data=id_data_build)[0]\n",
    "metadata_json = dao_processed.load_processed_metadata(id_data=id_data_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e138427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_features = remove_cols(cols=metadata_json[\"use_features\"], cols_to_remove=feature_selection_data[\"cols_to_remove\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08655e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_ttrain shape: (87470, 15)\n",
      "df_tvalid shape: (23468, 15)\n",
      "df_test shape: (72711, 14)\n"
     ]
    }
   ],
   "source": [
    "df_ttrain = dao_processed.load_processed_data(which_dataset=\"train_train\", id_data=id_data_build, spark=spark)\n",
    "df_ttrain = dflib.sample(df_ttrain, n=df_ttrain.count())\n",
    "df_tvalid = dao_processed.load_processed_data(which_dataset=\"train_valid\", id_data=id_data_build, spark=spark)\n",
    "df_test = dao_processed.load_processed_data(which_dataset=\"test\", id_data=id_data_build, spark=spark)\n",
    "\n",
    "print(f\"df_ttrain shape: {dflib.shape(df_ttrain)}\")\n",
    "print(f\"df_tvalid shape: {dflib.shape(df_tvalid)}\")\n",
    "print(f\"df_test shape: {dflib.shape(df_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8125cf",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cee2cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, IndexToString\n",
    "from src.ml.transformers import UndersamplingTransformer, ProbaVectorToPrediction\n",
    "from src.ml.estimators import FillProbaEstimator\n",
    "from src.ml import metrics\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed03a1b",
   "metadata": {},
   "source": [
    "### Defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4219f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampling_transformer = UndersamplingTransformer(target_colname=\"target\")\n",
    "\n",
    "feature_assembler_transformer = VectorAssembler(inputCols=use_features, \n",
    "                                                outputCol=\"features\")\n",
    "\n",
    "target_indexer_transformer = StringIndexer(inputCol=\"target\", \n",
    "                                           outputCol=\"target_indexed\", \n",
    "                                           stringOrderType=\"alphabetDesc\").fit(df_ttrain)\n",
    "labels = [target_indexer_transformer.labels[i] for i in range(len(target_indexer_transformer.labels))]\n",
    "\n",
    "target_reverter_transformer = IndexToString(inputCol=\"target_indexed\", \n",
    "                                            outputCol=\"target\",\n",
    "                                            labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46e27e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_train = PipelineModel(stages=[feature_assembler_transformer, \n",
    "                                       target_indexer_transformer])\n",
    "\n",
    "pipeline_test = PipelineModel(stages=[feature_assembler_transformer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe4662",
   "metadata": {},
   "source": [
    "### Applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a9cdd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_ttrain shape: (85353, 15)\n",
      "df_ttrain_na shape: (2117, 15)\n",
      "df_tvalid shape: (22807, 15)\n",
      "df_tvalid_na shape: (661, 15)\n",
      "df_test shape: (65795, 14)\n",
      "df_test_na shape: (6916, 14)\n"
     ]
    }
   ],
   "source": [
    "df_ttrain_na = dflib.filter_any_null(df_ttrain, subset=use_features)\n",
    "df_ttrain = DropNaTransformer(subset=use_features).transform(df_ttrain)\n",
    "\n",
    "df_tvalid_na = dflib.filter_any_null(df_tvalid, subset=use_features)\n",
    "df_tvalid = DropNaTransformer(subset=use_features).transform(df_tvalid)\n",
    "\n",
    "df_test_na = dflib.filter_any_null(df_test)\n",
    "df_test = DropNaTransformer().transform(df_test)\n",
    "\n",
    "print(f\"df_ttrain shape: {dflib.shape(df_ttrain)}\")\n",
    "print(f\"df_ttrain_na shape: {dflib.shape(df_ttrain_na)}\")\n",
    "print(f\"df_tvalid shape: {dflib.shape(df_tvalid)}\")\n",
    "print(f\"df_tvalid_na shape: {dflib.shape(df_tvalid_na)}\")\n",
    "print(f\"df_test shape: {dflib.shape(df_test)}\")\n",
    "print(f\"df_test_na shape: {dflib.shape(df_test_na)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5607883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ttrain = pipeline_train.transform(df_ttrain)\n",
    "df_ttrain_u = undersampling_transformer.transform(df_ttrain)\n",
    "df_tvalid = pipeline_train.transform(df_tvalid)\n",
    "df_tvalid_u = undersampling_transformer.transform(df_tvalid)\n",
    "df_test = pipeline_test.transform(df_test)\n",
    "\n",
    "df_ttrain_pd = df_ttrain.toPandas()\n",
    "df_ttrain_u_pd = df_ttrain_u.toPandas()\n",
    "df_tvalid_pd = df_tvalid.toPandas()\n",
    "df_test_pd = df_test.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd3f6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_ttrain.union(df_tvalid)\n",
    "df_train_pd = df_train.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13f74bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_u = undersampling_transformer.transform(df_ttrain.union(df_tvalid))\n",
    "df_train_u_pd = df_train_u.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9feee9",
   "metadata": {},
   "source": [
    "# Checking validation score with `tvalid` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ce10211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgb_algorithm(xgb_conf_row):\n",
    "    params = xgb_conf_row[\"params\"]\n",
    "    features = ast.literal_eval(xgb_conf_row[\"features\"])\n",
    "    \n",
    "    for k in params.keys():\n",
    "        if params[k] == 1.0 or k in [\"n_estimators\", \"max_depth\"]:\n",
    "            params[k] = int(params[k])\n",
    "    \n",
    "    params[\"use_label_encoder\"] = False\n",
    "    params[\"eval_metric\"] = \"logloss\"\n",
    "    xgbc = xgb.XGBClassifier(**params)\n",
    "    \n",
    "    return {\"clf\": xgbc, \"features\": features}\n",
    "\n",
    "def get_rf_algorithm(rf_conf_row):\n",
    "    params = rf_conf_row[\"params\"]\n",
    "    for k in params.keys():\n",
    "        if params[k] == 1.0 or k in [\"numTrees\", \"maxDepth\"]:\n",
    "            params[k] = int(params[k])\n",
    "\n",
    "    rfc = RandomForestClassifier(numTrees=params[\"numTrees\"], \n",
    "                                 maxDepth=params[\"maxDepth\"], \n",
    "                                 subsamplingRate=params[\"subsamplingRate\"])\n",
    "    rfc.setLabelCol(\"target_indexed\")\n",
    "    rfc.setFeaturesCol(\"features\")\n",
    "    rfc.setPredictionCol(\"prediction\")\n",
    "    rfc.setProbabilityCol(\"proba\")\n",
    "    \n",
    "    return rfc\n",
    "\n",
    "def predict_proba_xgb(clf, df, features, labels=labels):\n",
    "    proba = clf.predict_proba(df[features])\n",
    "    proba = pd.DataFrame(proba, columns=labels, index=df.index)\n",
    "    return proba.join(df[[\"target\"]], how=\"inner\")\n",
    "\n",
    "def predict_proba_rf(clf, df, features, target_to_string=target_reverter_transformer):\n",
    "    proba = clf.transform(df.select([\"features\", \"target_indexed\", \"target\"] + features))\n",
    "    if not \"target\" in proba.columns:\n",
    "        proba = target_to_string.transform(proba)\n",
    "    \n",
    "    return proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fd61bd",
   "metadata": {},
   "source": [
    "<b>Fitting</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cd2c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc_u_clf_df = results_rf_u \\\n",
    "#         .apply(get_rf_algorithm, axis=1) \\\n",
    "#         .apply(lambda rf : rf.fit(df_ttrain_u))\n",
    "\n",
    "# rfc_clf_df = results_rf \\\n",
    "#         .apply(get_rf_algorithm, axis=1) \\\n",
    "#         .apply(lambda rf : rf.fit(df_ttrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14ce1f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_u_clf_df = results_xgb_u \\\n",
    "        .apply(get_xgb_algorithm, axis=1) \\\n",
    "        .apply(lambda xgbc : xgbc[\"clf\"].fit(df_ttrain_u_pd[xgbc[\"features\"]], df_ttrain_u_pd[\"target_indexed\"]))\n",
    "\n",
    "xgbc_clf_df = results_xgb \\\n",
    "        .apply(get_xgb_algorithm, axis=1) \\\n",
    "        .apply(lambda xgbc : xgbc[\"clf\"].fit(df_ttrain_pd[xgbc[\"features\"]], df_ttrain_pd[\"target_indexed\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009efe8c",
   "metadata": {},
   "source": [
    "<b>Predicting</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7213210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc_u_preds_valid_df = rfc_u_clf_df.apply(lambda rfc : predict_proba_rf(rfc, df_tvalid, use_features))\n",
    "\n",
    "# rfc_preds_valid_df = rfc_clf_df.apply(lambda rfc : predict_proba_rf(rfc, df_tvalid, use_features))\n",
    "\n",
    "# rfc_u_preds_valid_df = rfc_u_preds_valid_df.apply(lambda df : dflib.dense_vector_to_columns(df=df,\n",
    "#                                                                dense_vector_colname=\"proba\",\n",
    "#                                                                new_colnames=labels).toPandas())\n",
    "\n",
    "# rfc_preds_valid_df = rfc_preds_valid_df.apply(lambda df : dflib.dense_vector_to_columns(df=df,\n",
    "#                                                                dense_vector_colname=\"proba\",\n",
    "#                                                                new_colnames=labels).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1236cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_u_preds_valid_df = xgbc_u_clf_df.apply(lambda xgbc : \n",
    "                                        predict_proba_xgb(clf=xgbc, df=df_tvalid_pd, features=use_features))\n",
    "\n",
    "xgbc_preds_valid_df = xgbc_clf_df.apply(lambda xgbc : \n",
    "                                        predict_proba_xgb(clf=xgbc, df=df_tvalid_pd, features=use_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48137f29",
   "metadata": {},
   "source": [
    "<b>Evaluating</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8f0531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_u_score_valid_df = xgbc_u_preds_valid_df.apply(lambda preds : log_loss(y_true=preds[\"target\"], y_pred=preds[labels].to_numpy()))\n",
    "xgbc_score_valid_df = xgbc_preds_valid_df.apply(lambda preds : log_loss(y_true=preds[\"target\"], y_pred=preds[labels].to_numpy()))\n",
    "\n",
    "# rfc_u_preds_valid_df = rfc_u_preds_valid_df.apply(lambda preds : log_loss(y_true=preds[\"target\"], y_pred=preds[labels].to_numpy()))\n",
    "# rfc_preds_valid_df = rfc_preds_valid_df.apply(lambda preds : log_loss(y_true=preds[\"target\"], y_pred=preds[labels].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18d080e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgbc_u_score_valid_df\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87    1.374880\n",
       "51    1.374880\n",
       "53    1.350037\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgbc_score_valid_df\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88    1.334647\n",
       "52    1.334647\n",
       "53    1.397094\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"xgbc_u_score_valid_df\")\n",
    "display(xgbc_u_score_valid_df)\n",
    "print()\n",
    "print(\"xgbc_score_valid_df\")\n",
    "display(xgbc_score_valid_df)\n",
    "print()\n",
    "# print(\"rfc_u_preds_valid_df\")\n",
    "# display(rfc_u_preds_valid_df)\n",
    "# print()\n",
    "# print(\"rfc_preds_valid_df\")\n",
    "# display(rfc_preds_valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f9e5991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.6,\n",
       "              enable_categorical=False, eval_metric='logloss', gamma=0,\n",
       "              gpu_id=-1, importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=60, n_jobs=12, num_parallel_tree=1,\n",
       "              objective='multi:softprob', predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=0.8,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, ...)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clf = results_xgb.loc[[\"53\"]] \\\n",
    "            .apply(get_xgb_algorithm, axis=1) \\\n",
    "            .apply(lambda xgbc : xgbc[\"clf\"].fit(df_ttrain_pd.append(df_tvalid_pd)[xgbc[\"features\"]], df_ttrain_pd.append(df_tvalid_pd)[\"target_indexed\"])).item()\n",
    "\n",
    "final_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3070ec5b",
   "metadata": {},
   "source": [
    "# Selecting Missing Values Strategy\n",
    "For dataset with <b>missing values</b> in features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a289ce8c",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c59e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_na_imputer(clf, df_train, df_valid, strategy='median'):\n",
    "    imputer = Imputer(strategy=strategy, inputCols=use_features, outputCols=use_features).fit(df_train)\n",
    "    df_valid_imputed = imputer.transform(df_valid)\n",
    "    df_valid_imputed = target_indexer_transformer.transform(df_valid_imputed)\n",
    "    \n",
    "    df_valid_imputed = df_valid_imputed.toPandas()\n",
    "    \n",
    "    preds_valid_imputed = clf.predict_proba(df_valid_imputed[use_features])\n",
    "    preds_valid_imputed = pd.DataFrame(preds_valid_imputed, columns=[int(c) for c in clf.classes_], index=df_valid_imputed[\"id\"])\n",
    "    \n",
    "    preds_valid_imputed = preds_valid_imputed.join(df_valid_imputed.set_index(\"id\"), how=\"right\")\n",
    "\n",
    "    \n",
    "    return preds_valid_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "738bcdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_tvalid_na_median_imputed = predict_na_imputer(final_clf, df_ttrain, df_tvalid_na, strategy='median')\n",
    "preds_tvalid_na_mean_imputed = predict_na_imputer(final_clf, df_ttrain, df_tvalid_na, strategy='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc372235",
   "metadata": {},
   "source": [
    "#### Filling Prediction with Global Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc0bb026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_na_filler(df_train, df_valid):\n",
    "    proba_filler = FillProbaEstimator(strategy=\"global_frequency\", labels=target_indexer_transformer.labels,\n",
    "                                      proba_vector_col=\"proba\").fit(df_train)\n",
    "\n",
    "    pred_indexer = ProbaVectorToPrediction(target_transformer=target_indexer_transformer, \n",
    "                                           prediction_col=\"prediction\",\n",
    "                                           dense_vector_colname=\"proba\")\n",
    "\n",
    "    df_valid_proba_filled = proba_filler.transform(df_valid)\n",
    "\n",
    "    if not \"away\" in df_valid_proba_filled.columns:\n",
    "        df_valid_proba_filled = pred_indexer.transform(df_valid_proba_filled)\n",
    "        \n",
    "    df_valid_proba_filled = target_indexer_transformer.transform(df_valid_proba_filled)\n",
    "    return df_valid_proba_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9853a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_tvalid_na_filled = predict_na_filler(df_ttrain, df_tvalid_na).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd882b8",
   "metadata": {},
   "source": [
    "#### Comparing missing values filling strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "269a7a47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_imputer (median): 661\n",
      "1.1572800701238926\n",
      "\n",
      "score_imputer (mean): 661\n",
      "1.1566998537139526\n",
      "\n",
      "score_filler: 661\n",
      "1.063540489975523\n"
     ]
    }
   ],
   "source": [
    "print(f\"score_imputer (median): {len(preds_tvalid_na_median_imputed)}\")\n",
    "print(log_loss(preds_tvalid_na_median_imputed[\"target_indexed\"], preds_tvalid_na_median_imputed[[0,1,2]].to_numpy()))\n",
    "print()\n",
    "print(f\"score_imputer (mean): {len(preds_tvalid_na_mean_imputed)}\")\n",
    "print(log_loss(preds_tvalid_na_mean_imputed[\"target_indexed\"], preds_tvalid_na_mean_imputed[[0,1,2]].to_numpy()))\n",
    "print()\n",
    "print(f\"score_filler: {len(preds_tvalid_na_filled)}\")\n",
    "print(log_loss(preds_tvalid_na_mean_imputed[\"target_indexed\"], preds_tvalid_na_filled[\"proba\"].to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf6a87b",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d007e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = final_clf.predict_proba(df_test_pd[use_features])\n",
    "preds_test = pd.DataFrame(preds_test, columns=[c for c in target_indexer_transformer.labels], index=df_test_pd[\"id\"])\n",
    "\n",
    "# preds_test_na = predict_na_imputer(final_clf, df_ttrain, df_test_na.toPandas())\n",
    "preds_test_na = predict_na_imputer(final_clf, df_ttrain.union(df_tvalid), df_test_na, strategy='median')\n",
    "preds_test_na = preds_test_na[[0,1,2]]\n",
    "preds_test_na.columns = [c for c in target_indexer_transformer.labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "17059516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72711"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(set(preds_test.columns).intersection(set(preds_test_na.columns)))\n",
    "\n",
    "preds = preds_test[cols].append(preds_test_na[cols])\n",
    "preds.columns = [target_indexer_transformer.labels[i] for i in range(3)]\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435599b8",
   "metadata": {},
   "source": [
    "# Build Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f5126bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.reset_index().to_csv(\"data/preds/preds57.csv\", index=False, sep=\",\") # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d290a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.reset_index().to_csv(\"data/preds/preds1313.csv\", index=False, sep=\",\") # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069186a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.toPandas().to_csv(\"data/preds/preds1212.csv\", index=False, sep=\",\") # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f780aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.toPandas().to_csv(\"data/preds/preds1111.csv\", index=False, sep=\",\") # 1.04262 undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572788a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.toPandas().to_csv(\"data/preds/preds1010.csv\", index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3735176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.toPandas().to_csv(\"data/preds/preds8888.csv\", index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172d2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.toPandas().to_csv(\"data/preds/preds7777.csv\", index=False, sep=\",\") #1.02029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9242088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.toPandas().to_csv(\"data/preds/preds6666.csv\", index=False, sep=\",\") #1.02059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e39b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.toPandas().to_csv(\"data/preds/preds5555.csv\", index=False, sep=\",\") #1.02231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74436b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_strategies = [\"global_frequency\", \"league_frequency\", \"uniform_proba\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab109e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_rf_classifier(params):\n",
    "    num_trees = params[\"num_trees\"]\n",
    "    max_depth = params[\"max_depth\"]\n",
    "    subsampling_rate = params[\"subsampling_rate\"]\n",
    "    \n",
    "    rf = RandomForestClassifier(labelCol=\"target_indexed\", \n",
    "                                predictionCol=\"prediction\",\n",
    "                                probabilityCol='proba', \n",
    "                                featuresCol=\"features\", \n",
    "                                numTrees=num_trees,\n",
    "                                maxDepth=max_depth,\n",
    "                                subsamplingRate=subsampling_rate)\n",
    "    \n",
    "    return rf\n",
    "    \n",
    "\n",
    "def pick_input_data(undersampling):\n",
    "    if undersampling:\n",
    "        X = df_ttrain_undersampling\n",
    "    else:\n",
    "        X = df_ttrain\n",
    "    \n",
    "    return X\n",
    "\n",
    "def calc_metrics(df_preds, which_dataset):                            \n",
    "    preds_metrics = metrics.get_metrics(df_preds, \n",
    "                                        labelCol=\"target_indexed\", \n",
    "                                        predictionCol=\"prediction\", \n",
    "                                        probabilityCol=\"proba\")\n",
    "    \n",
    "    preds_metrics[\"which_dataset\"] = which_dataset\n",
    "    return preds_metrics\n",
    "\n",
    "def build_result(model_params, metrics_train, metrics_valid, data_build_params, id_data_build, labels):\n",
    "    id_result = str(uuid.uuid4())\n",
    "    result = model_params\n",
    "    \n",
    "    result[\"metrics_train_train\"] = metrics_train\n",
    "    result[\"metrics_train_valid\"] = metrics_valid\n",
    "    result[\"id_result\"] = id_result\n",
    "    result[\"features\"] = data_build_params[\"use_features\"]\n",
    "    result[\"id_data_build\"] = id_data_build\n",
    "    result[\"datetime\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    result[\"labels\"] = labels\n",
    "    \n",
    "    return result\n",
    "\n",
    "missing_preds_dfs = {(\"ttrain\", \"global_frequency\"): pipeline_missing_preds_global_freq.transform(df_ttrain_na),\n",
    "                     (\"ttrain\", \"league_frequency\"): pipeline_missing_preds_league_freq.transform(df_ttrain_na),\n",
    "                     (\"ttrain\", \"uniform_proba\"): pipeline_missing_preds_uniform.transform(df_ttrain_na),\n",
    "                     (\"tvalid\", \"global_frequency\"): pipeline_missing_preds_global_freq.transform(df_tvalid_na),\n",
    "                     (\"tvalid\", \"league_frequency\"): pipeline_missing_preds_league_freq.transform(df_tvalid_na),\n",
    "                     (\"tvalid\", \"uniform_proba\"): pipeline_missing_preds_uniform.transform(df_tvalid_na)}\n",
    "\n",
    "def fill_missing_proba_matches(df_label, missing_values_strategy):\n",
    "    return missing_preds_dfs[(df_label, missing_values_strategy)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
