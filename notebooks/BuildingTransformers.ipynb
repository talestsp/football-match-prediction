{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed008c12",
   "metadata": {},
   "source": [
    "# BuildingTransformers\n",
    "Notebook to wrap the analysis into Transformer for ML Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e9bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from working_dir import set_wd\n",
    "set_wd()\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f5a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"BuildingTransformers\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770675a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.dao import dao_raw, dao_interim, columns\n",
    "from src.utils import dflib, stats, pretties, plot, plot_domain, palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretties.max_data_frame_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ca631",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_HOME = palette.PALETTE_TARGET[\"home\"]\n",
    "COLOR_DRAW = palette.PALETTE_TARGET[\"draw\"]\n",
    "COLOR_AWAY = palette.PALETTE_TARGET[\"away\"]\n",
    "\n",
    "COLOR_OPTIM = palette.PALETTE_MOOD[\"optimistic\"]\n",
    "COLOR_NEUTR = palette.PALETTE_MOOD[\"neutral\"]\n",
    "COLOR_PESSI = palette.PALETTE_MOOD[\"pessimistic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0db4ff",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d696c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrain = dao_interim.load_train_train_data(spark)\n",
    "drop_cols = columns.team_history_coach_colnames\n",
    "\n",
    "ttrain = ttrain.drop(*drop_cols)\n",
    "\n",
    "print(f\"ttrain: {dflib.shape(ttrain)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cols = ['id', 'target', 'home_team_name', 'away_team_name', \n",
    "              'match_date', 'league_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84deb3b2",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c1f6d6",
   "metadata": {},
   "source": [
    "* https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.Transformer.html#pyspark.ml.Transformer.transform\n",
    "* https://stackoverflow.com/questions/49734374/pyspark-ml-pipelines-are-custom-transformers-necessary-for-basic-preprocessing\n",
    "* https://www.oreilly.com/content/extend-spark-ml-for-your-own-modeltransformer-types/\n",
    "* https://www.youtube.com/watch?v=iO4ebMzj7t8&ab_channel=ManningPublications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339eb93",
   "metadata": {},
   "source": [
    "## Team Mood Diff Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.transformers_lib import team_mood_diff\n",
    "\n",
    "class TeamMoodDiffTransformer(Transformer):\n",
    "    def __init__(self, neutral_numeric_threshold, colnames=\"*\"):\n",
    "        self.neutral_numeric_threshold = neutral_numeric_threshold\n",
    "        self.colnames = colnames\n",
    "        \n",
    "    def _transform(self, df):\n",
    "        use_df = df.select(self.colnames)\n",
    "        df_transformed = team_mood_diff.build(use_df, self.neutral_numeric_threshold) \n",
    "        return df_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7efed7a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0627412e",
   "metadata": {},
   "source": [
    "## Team History Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1ac7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.transformers_lib import team_history_result\n",
    "\n",
    "class TeamHistoryResultTransformer(Transformer):\n",
    "    def __init__(self, colnames=\"*\"):\n",
    "        self.colnames = colnames\n",
    "        \n",
    "    def _transform(self, df):\n",
    "        use_df = df.select(self.colnames)\n",
    "        df_transformed = team_history_result.build(use_df) \n",
    "        return df_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b0157",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e19c4e3",
   "metadata": {},
   "source": [
    "## Home Factor Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1327e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_pipeline.transformers_lib import home_factor\n",
    "\n",
    "class HomeFactorTransformer(Transformer):\n",
    "    def __init__(self, colnames=\"*\"):\n",
    "        self.colnames = colnames\n",
    "        \n",
    "    def _transform(self, df):\n",
    "        use_df = df.select(self.colnames)\n",
    "        df_transformed = home_factor.build(use_df) \n",
    "        return df_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aa81a0",
   "metadata": {},
   "source": [
    "# Combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faca066",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"shape dataframe:\", dflib.shape(ttrain))\n",
    "original_columns = ttrain.columns\n",
    "\n",
    "ttrain = TeamMoodDiffTransformer(neutral_numeric_threshold=0.5).transform(ttrain)\n",
    "print(\"shape transformed:\", dflib.shape(ttrain))\n",
    "\n",
    "ttrain = TeamHistoryResultTransformer().transform(ttrain)\n",
    "print(\"shape transformed:\", dflib.shape(ttrain))\n",
    "\n",
    "ttrain = HomeFactorTransformer().transform(ttrain)\n",
    "print(\"shape transformed:\", dflib.shape(ttrain))\n",
    "\n",
    "final_columns = ttrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06663b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af820d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = list(set(final_columns) - set(original_columns))\n",
    "print(new_features)\n",
    "\n",
    "df_transformed = ttrain.select(basic_cols + new_features)\n",
    "print(\"shape transformed:\", dflib.shape(df_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef2a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflib.sample(df_transformed, 5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70afd788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
