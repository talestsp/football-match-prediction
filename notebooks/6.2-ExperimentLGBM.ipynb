{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8edfa13",
   "metadata": {},
   "source": [
    "# Experiment LGBM\n",
    "Grid Search + Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5969a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from working_dir import set_wd\n",
    "set_wd()\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bcbd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.config('spark.ui.showConsoleProgress', 'false') \\\n",
    "                            .config(\"spark.sql.debug.maxToStringFields\", 500) \\\n",
    "                            .config(\"spark.sql.debug.autoBroadcastJoinThreshold\", -1) \\\n",
    "                            .config(\"spark.driver.memory\", \"8g\") \\\n",
    "                            .appName(\"ExperimentXGBoost\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d4c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.dao import dao_processed, dao_ml\n",
    "from src.utils import dflib, stats, pretties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b287e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretties.max_data_frame_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec53605",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASIC_COLS = ['id', 'target', 'league_id', 'league_name',\n",
    "              'home_team_name', 'away_team_name', \n",
    "              'match_date']\n",
    "\n",
    "N_FOLDS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e7e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cols(cols, cols_to_remove):\n",
    "    for col_to_remove in cols_to_remove:\n",
    "        if col_to_remove in cols:\n",
    "            cols.remove(col_to_remove)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2aa38",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7874f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_data_build = dao_processed.most_recent_data_build_id()\n",
    "print(id_data_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4152d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_data = dao_ml.load_feature_selection(id_data=id_data_build)[0]\n",
    "metadata_json = dao_processed.load_processed_metadata(id_data=id_data_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_features = remove_cols(cols=metadata_json[\"use_features\"], cols_to_remove=feature_selection_data[\"cols_to_remove\"])\n",
    "use_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08655e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ttrain = dao_processed.load_processed_data(which_dataset=\"train_train\", id_data=id_data_build, spark=spark)\n",
    "print(f\"df_ttrain shape: {dflib.shape(df_ttrain)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8125cf",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee2cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import VectorAssembler #A feature transformer that merges multiple columns into a vector column.\n",
    "from pyspark.ml.feature import StringIndexer #A label indexer that maps a string column of labels to an ML column of label indices.\n",
    "from src.ml.transformers import DropNaTransformer, UndersamplingTransformer, DateFilterTransformer\n",
    "\n",
    "# import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from src.ml import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed03a1b",
   "metadata": {},
   "source": [
    "### Defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4219f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampling_transformer = UndersamplingTransformer(target_colname=\"target\")\n",
    "\n",
    "date_filter_transformer = DateFilterTransformer(\"match_date\", from_dt=FILTER_FROM_DT)\n",
    "\n",
    "target_indexer_transformer = StringIndexer(inputCol=\"target\", \n",
    "                                           outputCol=\"target_indexed\", \n",
    "                                           stringOrderType=\"alphabetDesc\").fit(df_ttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e27e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_train = PipelineModel(stages=[target_indexer_transformer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9cdd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"df_ttrain shape before: {dflib.shape(df_ttrain)}\")\n",
    "df_ttrain = DropNaTransformer(subset=use_features).transform(df_ttrain)\n",
    "print(f\"df_ttrain shape after: {dflib.shape(df_ttrain)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5607883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ttrain = dao_processed.load_processed_data(which_dataset=\"train_train\", id_data=id_data_build, spark=spark)\n",
    "df_tvalid = dao_processed.load_processed_data(which_dataset=\"train_valid\", id_data=id_data_build, spark=spark)\n",
    "\n",
    "print(f\"df_ttrain shape: {dflib.shape(df_ttrain)}\")\n",
    "print(f\"df_tvalid shape: {dflib.shape(df_tvalid)}\")\n",
    "\n",
    "df_train = df_ttrain.union(df_tvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c2a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pipeline_train.transform(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6030fd06",
   "metadata": {},
   "source": [
    "### Model, Params and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6401f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmc = LGBMClassifier()\n",
    "\n",
    "parameters = {'num_leaves': [5, 10, 20, 31], \n",
    "              'max_depth':[3, 5, 8, -1],\n",
    "              'colsample_bytree': [0.5, 0.6, 0.7],\n",
    "              'subsample': [0.4, 0.7],\n",
    "              'n_estimators': [20, 40, 60],\n",
    "              'learning_rate': [0.2, 0.4, 0.6]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lgbmc, \n",
    "                           param_grid=parameters,\n",
    "                           cv=KFold(N_FOLDS),\n",
    "                           scoring=\"neg_log_loss\", \n",
    "                           return_train_score=True,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56ea907",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "For dataset with no missing values in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a534dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.freq(df_train, \"target_indexed\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd4eb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t0 = datetime.now()\n",
    "df_train = df_train.toPandas().sample(df_train.count())\n",
    "# df_train[\"is_cup\"] = df_train[\"is_cup\"].replace({True: 1, False:0})\n",
    "\n",
    "grid_search_model = grid_search.fit(df_train[use_features], df_train[\"target_indexed\"])\n",
    "tf = datetime.now()\n",
    "print((tf - t0).total_seconds(), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cedb2d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = grid_search_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4ae227",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best_score\")\n",
    "print(grid_search_model.best_score_)\n",
    "\n",
    "print(\"best_params\")\n",
    "print(grid_search_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acbd403",
   "metadata": {},
   "outputs": [],
   "source": [
    "of_df = metrics.build_overfitting_analysis_df_xgboost(grid_search_model=grid_search_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88887d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = get_feature_importances(clf, use_features)\n",
    "display(feature_importances)\n",
    "feature_importances.plot.bar(figsize=(12, 5), rot=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8590e6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dao_ml.save_modeling_xgboost(id_data=id_data_build, \n",
    "                             grid_search_model=grid_search_model, \n",
    "                             features=use_features, \n",
    "                             overfitting_analysis_df=of_df, \n",
    "                             pipeline_train=pipeline_train,\n",
    "                             n_fold=N_FOLDS,\n",
    "                             grid_search_time=(tf-t0).total_seconds())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
