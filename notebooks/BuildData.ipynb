{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed008c12",
   "metadata": {},
   "source": [
    "# BuildData\n",
    "Notebook to build and save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e9bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from working_dir import set_wd\n",
    "set_wd()\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f5a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.sql.debug.maxToStringFields\", 500) \\\n",
    "                            .config(\"spark.driver.memory\", \"14g\") \\\n",
    "                            .appName(\"BuldData\").getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770675a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import when\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from src.dao import dao_raw, dao_interim, dao_processed, columns\n",
    "from src.utils import dflib, stats, pretties, plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretties.max_data_frame_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0627412e",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml.transformers import TeamMoodDiffTransformer, \\\n",
    "                                TeamHistoryResultTransformer, \\\n",
    "                                HomeFactorTransformer, \\\n",
    "                                SelectColumnsTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c929574",
   "metadata": {},
   "source": [
    "# Build Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f329b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_features = ['home_mood_diff', 'away_mood_diff', \n",
    "                'home_history_mood_mean', 'away_history_mood_mean',\n",
    "                'home_result_history_mean', 'away_result_history_mean',\n",
    "                'home_factor', 'draw_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f180f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_stages=[TeamMoodDiffTransformer(), \n",
    "                 TeamHistoryResultTransformer(), \n",
    "                 HomeFactorTransformer(spark=spark),\n",
    "                 SelectColumnsTransformer(subset_colnames=use_features)]\n",
    "\n",
    "pipeline_model = PipelineModel(stages=pipeline_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61969653",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = str(uuid.uuid4())\n",
    "pretties.md(f'id: {id}', size=\"####\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7566be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_json = {}\n",
    "\n",
    "for stage in pipeline_stages:\n",
    "    metadata_json[stage.__class__.__name__] = stage.get_params()\n",
    "    \n",
    "metadata_json[\"datetime\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "metadata_json[\"id\"] = id\n",
    "metadata_json[\"use_features\"] = use_features\n",
    "\n",
    "dao_processed.save_processed_metadata(metadata_json, id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23bb51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cols = ['id', 'target', 'home_team_name', 'away_team_name', \n",
    "              'match_date', 'league_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9836691",
   "metadata": {},
   "outputs": [],
   "source": [
    "for which_dataset in [\"train_train\", \"train_valid\", \"test\"]:\n",
    "    print(f'which_dataset: {which_dataset}')\n",
    "    print(f'id: {id}')\n",
    "    print()\n",
    "    print(\"loading data\")\n",
    "    \n",
    "    if which_dataset == \"train_train\":\n",
    "        df = dao_interim.load_train_train_data(spark)\n",
    "        \n",
    "    elif which_dataset == \"train_valid\":\n",
    "        df = dao_interim.load_train_valid_data(spark)\n",
    "\n",
    "    elif which_dataset == \"test\":\n",
    "        df = dao_raw.load_parse_test_data(spark)\n",
    "\n",
    "    \n",
    "    drop_cols = columns.team_history_coach_colnames\n",
    "    df = df.drop(*drop_cols)\n",
    "\n",
    "    print(f\"df: {dflib.shape(df)}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"processing\")\n",
    "    df_processed = pipeline_model.transform(df)\n",
    "    print()\n",
    "    \n",
    "    print(\"saving\")\n",
    "    dao_processed.save_processed_data(df_processed, which_dataset, id)\n",
    "    pretties.hr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa12f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5492e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
