{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8edfa13",
   "metadata": {},
   "source": [
    "# Build Best Model And Predict\n",
    "Notebook to get the best params, builds, predicts and make submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5969a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tales/ds/kaggle/football-match-prediction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from working_dir import set_wd\n",
    "set_wd()\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48bcbd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/26 20:01:48 WARN Utils: Your hostname, tales-samsung resolves to a loopback address: 127.0.1.1; using 192.168.0.102 instead (on interface wlp1s0)\n",
      "22/05/26 20:01:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/26 20:01:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.config('spark.ui.showConsoleProgress', 'false') \\\n",
    "                            .config(\"spark.sql.debug.maxToStringFields\", 500) \\\n",
    "                            .config(\"spark.sql.debug.autoBroadcastJoinThreshold\", -1) \\\n",
    "                            .config(\"spark.driver.memory\", \"10g\") \\\n",
    "                            .appName(\"BuildBestModelAndPredict\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82d4c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.dao import dao_processed, dao_ml\n",
    "from src.utils import dflib, stats, pretties\n",
    "from src.ml.transformers import DropNaTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b287e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretties.max_data_frame_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac7ccc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cols(cols, cols_to_remove):\n",
    "    for col_to_remove in cols_to_remove:\n",
    "        if col_to_remove in cols:\n",
    "            cols.remove(col_to_remove)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd6612c",
   "metadata": {},
   "source": [
    "# Loading Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e08f5207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_modeling</th>\n",
       "      <th>datetime</th>\n",
       "      <th>clf_name</th>\n",
       "      <th>undersampling</th>\n",
       "      <th>n_features</th>\n",
       "      <th>best_score_cv_train</th>\n",
       "      <th>best_score_cv</th>\n",
       "      <th>clf_params</th>\n",
       "      <th>features</th>\n",
       "      <th>id_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9bd15ac0-889a-4cf5-9012-5675edce5889</td>\n",
       "      <td>2022-05-26 16:37:12</td>\n",
       "      <td>RandomForestClassificationModel</td>\n",
       "      <td>balanced</td>\n",
       "      <td>8</td>\n",
       "      <td>1.001444</td>\n",
       "      <td>1.000331</td>\n",
       "      <td>{'numTrees': 60, 'maxDepth': 10, 'subsamplingR...</td>\n",
       "      <td>[home_mood_diff, draw_factor, home_history_moo...</td>\n",
       "      <td>b2beffb2-fb6d-4cb4-8869-82b859c2dd3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d6e238c1-c6a8-41be-ac18-3cad3f47a420</td>\n",
       "      <td>2022-05-26 16:44:32</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>no</td>\n",
       "      <td>8</td>\n",
       "      <td>0.996144</td>\n",
       "      <td>1.010365</td>\n",
       "      <td>{'colsample_bytree': 0.7, 'max_depth': 4, 'n_e...</td>\n",
       "      <td>[home_mood_diff, draw_factor, away_history_moo...</td>\n",
       "      <td>b2beffb2-fb6d-4cb4-8869-82b859c2dd3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6d671cab-ea98-4471-8455-0a8092241123</td>\n",
       "      <td>2022-05-26 15:52:32</td>\n",
       "      <td>RandomForestClassificationModel</td>\n",
       "      <td>no</td>\n",
       "      <td>8</td>\n",
       "      <td>0.982310</td>\n",
       "      <td>1.012607</td>\n",
       "      <td>{'numTrees': 60, 'maxDepth': 10, 'subsamplingR...</td>\n",
       "      <td>[home_mood_diff, away_history_mood_mean, home_...</td>\n",
       "      <td>b2beffb2-fb6d-4cb4-8869-82b859c2dd3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3f709ede-053d-434d-a212-867de706844b</td>\n",
       "      <td>2022-05-26 17:45:35</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>balanced</td>\n",
       "      <td>8</td>\n",
       "      <td>1.033072</td>\n",
       "      <td>1.039629</td>\n",
       "      <td>{'colsample_bytree': 0.7, 'max_depth': 2, 'n_e...</td>\n",
       "      <td>[home_mood_diff, home_history_mood_mean, away_...</td>\n",
       "      <td>b2beffb2-fb6d-4cb4-8869-82b859c2dd3b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id_modeling             datetime  \\\n",
       "0  9bd15ac0-889a-4cf5-9012-5675edce5889  2022-05-26 16:37:12   \n",
       "3  d6e238c1-c6a8-41be-ac18-3cad3f47a420  2022-05-26 16:44:32   \n",
       "1  6d671cab-ea98-4471-8455-0a8092241123  2022-05-26 15:52:32   \n",
       "2  3f709ede-053d-434d-a212-867de706844b  2022-05-26 17:45:35   \n",
       "\n",
       "                          clf_name undersampling  n_features  \\\n",
       "0  RandomForestClassificationModel      balanced           8   \n",
       "3                    XGBClassifier            no           8   \n",
       "1  RandomForestClassificationModel            no           8   \n",
       "2                    XGBClassifier      balanced           8   \n",
       "\n",
       "   best_score_cv_train  best_score_cv  \\\n",
       "0             1.001444       1.000331   \n",
       "3             0.996144       1.010365   \n",
       "1             0.982310       1.012607   \n",
       "2             1.033072       1.039629   \n",
       "\n",
       "                                          clf_params  \\\n",
       "0  {'numTrees': 60, 'maxDepth': 10, 'subsamplingR...   \n",
       "3  {'colsample_bytree': 0.7, 'max_depth': 4, 'n_e...   \n",
       "1  {'numTrees': 60, 'maxDepth': 10, 'subsamplingR...   \n",
       "2  {'colsample_bytree': 0.7, 'max_depth': 2, 'n_e...   \n",
       "\n",
       "                                            features  \\\n",
       "0  [home_mood_diff, draw_factor, home_history_moo...   \n",
       "3  [home_mood_diff, draw_factor, away_history_moo...   \n",
       "1  [home_mood_diff, away_history_mood_mean, home_...   \n",
       "2  [home_mood_diff, home_history_mood_mean, away_...   \n",
       "\n",
       "                                id_data  \n",
       "0  b2beffb2-fb6d-4cb4-8869-82b859c2dd3b  \n",
       "3  b2beffb2-fb6d-4cb4-8869-82b859c2dd3b  \n",
       "1  b2beffb2-fb6d-4cb4-8869-82b859c2dd3b  \n",
       "2  b2beffb2-fb6d-4cb4-8869-82b859c2dd3b  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = dao_ml.load_all_modeling()\n",
    "print(len(all_results))\n",
    "\n",
    "all_results_df = pd.DataFrame(all_results)\n",
    "all_results_df[\"undersampling\"] = all_results_df[\"pipeline_train_stages\"].apply(lambda ppl : \"UndersamplingTransformer\" in ppl)\n",
    "\n",
    "all_results_df[\"undersampling\"] = all_results_df[\"undersampling\"].replace({True: \"balanced\", False: \"no\"})\n",
    "\n",
    "all_results_df[\"features\"] = all_results_df[\"feature_importances\"].apply(lambda fi : list(fi[\"importance\"].keys()))\n",
    "all_results_df[\"n_features\"] = all_results_df[\"features\"].apply(len)\n",
    "all_results_df[[\"id_modeling\", \"datetime\", \"clf_name\", \"undersampling\", \"n_features\",\n",
    "                 \"best_score_cv_train\", \"best_score_cv\", \"clf_params\", \"features\", \"id_data\"]].sort_values(\"best_score_cv\", ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2aa38",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b615b8",
   "metadata": {},
   "source": [
    "The data loaded bellow is placed in a dictionary along with its id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c750ea",
   "metadata": {},
   "source": [
    "<b>Feature Selection</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4152d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection = {}\n",
    "features = {}\n",
    "metadata = {}\n",
    "\n",
    "for id_data in all_results_df[\"id_data\"].unique():\n",
    "    feature_selection_data = pd.DataFrame(dao_ml.load_feature_selection(id_data=id_data)).sort_values(\"datetime\").iloc[-1].to_dict()\n",
    "    metadata_json = dao_processed.load_processed_metadata(id_data=id_data)\n",
    "    \n",
    "    features[id_data] = remove_cols(cols=metadata_json[\"use_features\"], cols_to_remove=feature_selection_data[\"cols_to_remove\"])\n",
    "    feature_selection[id_data] = feature_selection_data\n",
    "    metadata[id_data] = metadata_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5b2ab7",
   "metadata": {},
   "source": [
    "<b>Data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9bfea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_processed_train(id_data):\n",
    "    return dao_processed.load_processed_data(which_dataset=\"train_train\", id_data=id_data, spark=spark) \\\n",
    "            .union(dao_processed.load_processed_data(which_dataset=\"train_valid\", id_data=id_data, spark=spark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08655e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_data: b2beffb2-fb6d-4cb4-8869-82b859c2dd3b\n",
      "train shape: (110938, 16)\n",
      "test shape : (72711, 15)\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for id_data in all_results_df[\"id_data\"].unique():\n",
    "    print(f\"id_data: {id_data}\")\n",
    "    data[id_data] = {}\n",
    "    \n",
    "    df_train = load_processed_train(id_data)\n",
    "    df_train = dflib.sample(df_train, n=df_train.count()) #shuffling train data\n",
    "    data[id_data][\"train\"] = df_train\n",
    "\n",
    "    df_test = dao_processed.load_processed_data(which_dataset=\"test\", id_data=id_data, spark=spark)\n",
    "    data[id_data][\"test\"] = df_test\n",
    "    \n",
    "    print(f\"train shape: {dflib.shape(df_train)}\")\n",
    "    print(f\"test shape : {dflib.shape(df_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8125cf",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cee2cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, IndexToString\n",
    "from src.ml.transformers import UndersamplingTransformer, ProbaVectorToPrediction\n",
    "from src.ml.estimators import FillProbaEstimator\n",
    "from src.ml import metrics\n",
    "from src.ml import missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed03a1b",
   "metadata": {},
   "source": [
    "### Defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4219f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampling_transformer = UndersamplingTransformer(target_colname=\"target\")\n",
    "\n",
    "target_indexer_transformer = StringIndexer(inputCol=\"target\", \n",
    "                                           outputCol=\"target_indexed\", \n",
    "                                           stringOrderType=\"alphabetDesc\").fit(df_train)\n",
    "labels = [target_indexer_transformer.labels[i] for i in range(len(target_indexer_transformer.labels))]\n",
    "\n",
    "target_reverter_transformer = IndexToString(inputCol=\"target_indexed\", \n",
    "                                            outputCol=\"target\",\n",
    "                                            labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe4662",
   "metadata": {},
   "source": [
    "### Applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "964910f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_data: b2beffb2-fb6d-4cb4-8869-82b859c2dd3b\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id_data in all_results_df[\"id_data\"].unique():\n",
    "    print(f\"id_data: {id_data}\")\n",
    "    use_features = features[id_data].copy()\n",
    "    \n",
    "    feature_assembler_transformer = VectorAssembler(inputCols=use_features, \n",
    "                                                    outputCol=\"features\")\n",
    "\n",
    "    pipeline_train = PipelineModel(stages=[feature_assembler_transformer, \n",
    "                                           target_indexer_transformer])\n",
    "\n",
    "    pipeline_test = PipelineModel(stages=[feature_assembler_transformer])\n",
    "\n",
    "    \n",
    "    df_train = data[id_data][\"train\"]\n",
    "    df_test = data[id_data][\"test\"]\n",
    "    \n",
    "    df_train_na = dflib.filter_any_null(df_train, subset=use_features)\n",
    "    df_train = DropNaTransformer(subset=use_features).transform(df_train)\n",
    "    \n",
    "    df_train = pipeline_train.transform(df_train)\n",
    "    df_train_u = undersampling_transformer.transform(df_train) #undersampling\n",
    "    \n",
    "    data[id_data][\"train\"] = df_train\n",
    "    data[id_data][\"train_balanced\"] = df_train_u\n",
    "    data[id_data][\"train_na\"] = df_train_na \n",
    "    \n",
    "    \n",
    "    df_test_na = dflib.filter_any_null(df_test)\n",
    "    df_test = DropNaTransformer().transform(df_test)\n",
    "    df_test = pipeline_test.transform(df_test) \n",
    "    \n",
    "    data[id_data][\"test\"] = df_test\n",
    "    data[id_data][\"test_na\"] = df_test_na\n",
    "    \n",
    "    df_train = data[id_data][\"train\"]\n",
    "    df_test = data[id_data][\"test\"]\n",
    "    \n",
    "    train_na_imputed_median = pipeline_train.transform(\n",
    "        missing_values.imputer(df_train, df_train_na, use_features, 'median'))\n",
    "    train_na_imputed_mean = pipeline_train.transform(\n",
    "        missing_values.imputer(df_train, df_train_na, use_features, 'mean'))\n",
    "    \n",
    "    data[id_data][\"train_na_imputed_median\"] = train_na_imputed_median \n",
    "    data[id_data][\"train_na_imputed_mean\"] = train_na_imputed_mean \n",
    "    \n",
    "    \n",
    "    df_test_na_imputed_median = pipeline_test.transform(\n",
    "        missing_values.imputer(df_train, df_test_na, use_features, 'median'))\n",
    "    df_test_na_imputed_mean = pipeline_test.transform(\n",
    "        missing_values.imputer(df_train, df_test_na, use_features, 'mean'))\n",
    "    \n",
    "    data[id_data][\"test_na_imputed_median\"] = df_test_na_imputed_median\n",
    "    data[id_data][\"test_na_imputed_mean\"] = df_test_na_imputed_mean\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b994a5",
   "metadata": {},
   "source": [
    "# Fit and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87aeb04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62bfb887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_params(params):\n",
    "    for k in params.keys():\n",
    "        if params[k] == 1.0 or k in [\"n_estimators\", \"max_depth\"]:\n",
    "            params[k] = int(params[k])\n",
    "    return params\n",
    "\n",
    "def get_xgb_algorithm(params, df_train, features):\n",
    "    params = clean_params(params)\n",
    "    params[\"use_label_encoder\"] = False\n",
    "    params[\"eval_metric\"] = \"logloss\"\n",
    "    \n",
    "    xgbc = xgb.XGBClassifier(**params)\n",
    "    \n",
    "    df_train_pd = df_train[features + [\"target_indexed\"]].toPandas()\n",
    "    \n",
    "    return xgbc.fit(df_train_pd[features], df_train_pd[\"target_indexed\"])\n",
    "\n",
    "def get_rf_algorithm(params, df_train, features):\n",
    "    params = clean_params(params)\n",
    "\n",
    "    rfc = RandomForestClassifier(numTrees=params[\"numTrees\"], \n",
    "                                 maxDepth=params[\"maxDepth\"], \n",
    "                                 subsamplingRate=params[\"subsamplingRate\"])\n",
    "    rfc.setLabelCol(\"target_indexed\")\n",
    "    rfc.setFeaturesCol(\"features\")\n",
    "    rfc.setPredictionCol(\"prediction\")\n",
    "    rfc.setProbabilityCol(\"proba\")\n",
    "    \n",
    "    return rfc.fit(df_train)\n",
    "\n",
    "def fit(result_row, data):\n",
    "    clf_name = result_row[\"clf_name\"]\n",
    "    id_data = result_row[\"id_data\"]\n",
    "    id_modeling = result_row[\"id_modeling\"]\n",
    "    features = result_row[\"features\"]\n",
    "    \n",
    "    if result_row[\"undersampling\"] == \"balanced\":\n",
    "        df_train = data[id_data][\"train_balanced\"]\n",
    "        \n",
    "    elif result_row[\"undersampling\"] == \"no\":\n",
    "        df_train = data[id_data][\"train\"]\n",
    "    \n",
    "    else:\n",
    "        raise Exception(f'undersampling not recognized: {result_row[\"undersampling\"]}')\n",
    "        \n",
    "    \n",
    "    if clf_name == \"RandomForestClassificationModel\":\n",
    "        clf = get_rf_algorithm(params=result_row[\"clf_params\"], df_train=df_train, features=features)\n",
    "        \n",
    "    elif clf_name == \"XGBClassifier\":\n",
    "        clf = get_xgb_algorithm(params=result_row[\"clf_params\"], df_train=df_train, features=features)\n",
    "        \n",
    "    return clf\n",
    "\n",
    "def predict(result_row, data, labels, test_dataset_name):\n",
    "    clf_name = result_row[\"clf_name\"]\n",
    "    id_data = result_row[\"id_data\"]\n",
    "    id_modeling = result_row[\"id_modeling\"]\n",
    "    features = result_row[\"features\"]\n",
    "    clf = result_row[\"clf\"]\n",
    "    \n",
    "    df_test = data[id_data][test_dataset_name]\n",
    "    \n",
    "    if clf_name == \"RandomForestClassificationModel\":\n",
    "        preds = clf.transform(df_test)\n",
    "        preds = dflib.dense_vector_to_columns(df=preds, \n",
    "                              dense_vector_colname=\"proba\", \n",
    "                              new_colnames=labels)[[\"id\"] + labels].toPandas()\n",
    "        \n",
    "    elif clf_name == \"XGBClassifier\":\n",
    "        df_test_pd = df_test[[\"id\"] + features].toPandas()\n",
    "        preds = clf.predict_proba(df_test_pd[features])\n",
    "        preds = pd.DataFrame(preds, columns=labels, index=df_test_pd[\"id\"]).reset_index()\n",
    "        \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b7c7d",
   "metadata": {},
   "source": [
    "<b>Fitting</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff2c413b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/26 20:02:27 WARN DAGScheduler: Broadcasting large task binary with size 1294.1 KiB\n",
      "22/05/26 20:02:30 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "22/05/26 20:02:33 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n",
      "22/05/26 20:02:36 WARN DAGScheduler: Broadcasting large task binary with size 1206.2 KiB\n",
      "22/05/26 20:02:38 WARN DAGScheduler: Broadcasting large task binary with size 7.7 MiB\n",
      "22/05/26 20:02:43 WARN DAGScheduler: Broadcasting large task binary with size 1996.1 KiB\n",
      "22/05/26 20:03:00 WARN DAGScheduler: Broadcasting large task binary with size 1192.6 KiB\n",
      "22/05/26 20:03:05 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "22/05/26 20:03:12 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n",
      "22/05/26 20:03:20 WARN DAGScheduler: Broadcasting large task binary with size 1261.0 KiB\n",
      "22/05/26 20:03:21 WARN DAGScheduler: Broadcasting large task binary with size 7.9 MiB\n",
      "22/05/26 20:03:31 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n"
     ]
    }
   ],
   "source": [
    "all_results_df[\"clf\"] = all_results_df.apply(lambda row: fit(row, data), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350c21d8",
   "metadata": {},
   "source": [
    "<b>Predicting</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46285798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/26 20:03:54 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n",
      "22/05/26 20:03:58 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n"
     ]
    }
   ],
   "source": [
    "all_results_df[\"preds\"] = all_results_df.apply(lambda row : predict(row, data, labels, \"test\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d3cef8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/26 20:04:02 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n",
      "22/05/26 20:04:04 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n"
     ]
    }
   ],
   "source": [
    "all_results_df[\"preds_na\"] = all_results_df.apply(lambda row : predict(row, data, labels, \"test_na_imputed_median\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d358e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_df[\"preds_complete\"] = all_results_df[[\"preds\", \"preds_na\"]].apply(lambda row : row[\"preds\"].append(row[\"preds_na\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435599b8",
   "metadata": {},
   "source": [
    "# Build Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f26ad039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/preds/preds_9bd15ac0-889a-4cf5-9012-5675edce5889.csv 72711\n",
      "data/preds/preds_6d671cab-ea98-4471-8455-0a8092241123.csv 72711\n",
      "data/preds/preds_3f709ede-053d-434d-a212-867de706844b.csv 72711\n",
      "data/preds/preds_d6e238c1-c6a8-41be-ac18-3cad3f47a420.csv 72711\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "def save_submission(preds_row):\n",
    "    filepath = \"data/preds/preds_\" + preds_row[\"id_modeling\"] + \".csv\"\n",
    "    submission_df = preds_row[\"preds_complete\"]\n",
    "    print(filepath, len(submission_df))\n",
    "    submission_df.to_csv(filepath, index=False)\n",
    "    \n",
    "all_results_df.apply(save_submission, axis=1)\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a9bc287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_modeling</th>\n",
       "      <th>datetime</th>\n",
       "      <th>clf_name</th>\n",
       "      <th>undersampling</th>\n",
       "      <th>n_features</th>\n",
       "      <th>best_score_cv_train</th>\n",
       "      <th>best_score_cv</th>\n",
       "      <th>clf_params</th>\n",
       "      <th>features</th>\n",
       "      <th>id_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9bd15ac0-889a-4cf5-9012-5675edce5889</td>\n",
       "      <td>2022-05-26 16:37:12</td>\n",
       "      <td>RandomForestClassificationModel</td>\n",
       "      <td>balanced</td>\n",
       "      <td>8</td>\n",
       "      <td>1.001444</td>\n",
       "      <td>1.000331</td>\n",
       "      <td>{'numTrees': 60, 'maxDepth': 10, 'subsamplingR...</td>\n",
       "      <td>[home_mood_diff, draw_factor, home_history_moo...</td>\n",
       "      <td>b2beffb2-fb6d-4cb4-8869-82b859c2dd3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d6e238c1-c6a8-41be-ac18-3cad3f47a420</td>\n",
       "      <td>2022-05-26 16:44:32</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>no</td>\n",
       "      <td>8</td>\n",
       "      <td>0.996144</td>\n",
       "      <td>1.010365</td>\n",
       "      <td>{'colsample_bytree': 0.7, 'max_depth': 4, 'n_e...</td>\n",
       "      <td>[home_mood_diff, draw_factor, away_history_moo...</td>\n",
       "      <td>b2beffb2-fb6d-4cb4-8869-82b859c2dd3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6d671cab-ea98-4471-8455-0a8092241123</td>\n",
       "      <td>2022-05-26 15:52:32</td>\n",
       "      <td>RandomForestClassificationModel</td>\n",
       "      <td>no</td>\n",
       "      <td>8</td>\n",
       "      <td>0.982310</td>\n",
       "      <td>1.012607</td>\n",
       "      <td>{'numTrees': 60, 'maxDepth': 10, 'subsamplingR...</td>\n",
       "      <td>[home_mood_diff, away_history_mood_mean, home_...</td>\n",
       "      <td>b2beffb2-fb6d-4cb4-8869-82b859c2dd3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3f709ede-053d-434d-a212-867de706844b</td>\n",
       "      <td>2022-05-26 17:45:35</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>balanced</td>\n",
       "      <td>8</td>\n",
       "      <td>1.033072</td>\n",
       "      <td>1.039629</td>\n",
       "      <td>{'colsample_bytree': 0.7, 'max_depth': 2, 'n_e...</td>\n",
       "      <td>[home_mood_diff, home_history_mood_mean, away_...</td>\n",
       "      <td>b2beffb2-fb6d-4cb4-8869-82b859c2dd3b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id_modeling             datetime  \\\n",
       "0  9bd15ac0-889a-4cf5-9012-5675edce5889  2022-05-26 16:37:12   \n",
       "3  d6e238c1-c6a8-41be-ac18-3cad3f47a420  2022-05-26 16:44:32   \n",
       "1  6d671cab-ea98-4471-8455-0a8092241123  2022-05-26 15:52:32   \n",
       "2  3f709ede-053d-434d-a212-867de706844b  2022-05-26 17:45:35   \n",
       "\n",
       "                          clf_name undersampling  n_features  \\\n",
       "0  RandomForestClassificationModel      balanced           8   \n",
       "3                    XGBClassifier            no           8   \n",
       "1  RandomForestClassificationModel            no           8   \n",
       "2                    XGBClassifier      balanced           8   \n",
       "\n",
       "   best_score_cv_train  best_score_cv  \\\n",
       "0             1.001444       1.000331   \n",
       "3             0.996144       1.010365   \n",
       "1             0.982310       1.012607   \n",
       "2             1.033072       1.039629   \n",
       "\n",
       "                                          clf_params  \\\n",
       "0  {'numTrees': 60, 'maxDepth': 10, 'subsamplingR...   \n",
       "3  {'colsample_bytree': 0.7, 'max_depth': 4, 'n_e...   \n",
       "1  {'numTrees': 60, 'maxDepth': 10, 'subsamplingR...   \n",
       "2  {'colsample_bytree': 0.7, 'max_depth': 2, 'n_e...   \n",
       "\n",
       "                                            features  \\\n",
       "0  [home_mood_diff, draw_factor, home_history_moo...   \n",
       "3  [home_mood_diff, draw_factor, away_history_moo...   \n",
       "1  [home_mood_diff, away_history_mood_mean, home_...   \n",
       "2  [home_mood_diff, home_history_mood_mean, away_...   \n",
       "\n",
       "                                id_data  \n",
       "0  b2beffb2-fb6d-4cb4-8869-82b859c2dd3b  \n",
       "3  b2beffb2-fb6d-4cb4-8869-82b859c2dd3b  \n",
       "1  b2beffb2-fb6d-4cb4-8869-82b859c2dd3b  \n",
       "2  b2beffb2-fb6d-4cb4-8869-82b859c2dd3b  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_df[[\"id_modeling\", \"datetime\", \"clf_name\", \"undersampling\", \"n_features\",\n",
    "                 \"best_score_cv_train\", \"best_score_cv\", \"clf_params\", \"features\", \"id_data\"]].sort_values(\"best_score_cv\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65cfb87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
