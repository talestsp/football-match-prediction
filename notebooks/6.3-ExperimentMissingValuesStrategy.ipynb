{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8edfa13",
   "metadata": {},
   "source": [
    "# Experiment Missing Values Strategy\n",
    "Try different Missing Values Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5969a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tales/ds/kaggle/football-match-prediction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from working_dir import set_wd\n",
    "set_wd()\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48bcbd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/23 16:54:20 WARN Utils: Your hostname, tales-samsung resolves to a loopback address: 127.0.1.1; using 192.168.0.107 instead (on interface wlxd03745e80dbf)\n",
      "22/05/23 16:54:20 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/23 16:54:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.config('spark.ui.showConsoleProgress', 'false') \\\n",
    "                            .config(\"spark.sql.debug.maxToStringFields\", 500) \\\n",
    "                            .config(\"spark.sql.debug.autoBroadcastJoinThreshold\", -1) \\\n",
    "                            .config(\"spark.driver.memory\", \"12g\") \\\n",
    "                            .appName(\"ExperimentMissingValuesStrategy\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82d4c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import when\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.dao import dao, dao_processed, dao_ml\n",
    "from src.utils import dflib, stats, pretties, plot, plot_domain, palette\n",
    "from src.ml.transformers import DropNaTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b287e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretties.max_data_frame_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ec53605",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASIC_COLS = ['id', 'target', 'league_id', 'league_name',\n",
    "              'home_team_name', 'away_team_name', \n",
    "              'match_date']\n",
    "\n",
    "N_FOLDS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83e7e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cols(cols, cols_to_remove):\n",
    "    for col_to_remove in cols_to_remove:\n",
    "        if col_to_remove in cols:\n",
    "            cols.remove(col_to_remove)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2aa38",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7874f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_data_build = dao_processed.most_recent_data_build_id()\n",
    "print(id_data_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4152d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_data = dao_ml.load_feature_selection(id_data=id_data_build)[0]\n",
    "metadata_json = dao_processed.load_processed_metadata(id_data=id_data_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_features = remove_cols(cols=metadata_json[\"use_features\"], cols_to_remove=feature_selection_data[\"cols_to_remove\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08655e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ttrain = dao_processed.load_processed_data(which_dataset=\"train_train\", id_data=id_data_build, spark=spark)\n",
    "df_ttrain = dflib.sample(df_ttrain, n=df_ttrain.count())\n",
    "df_tvalid = dao_processed.load_processed_data(which_dataset=\"train_valid\", id_data=id_data_build, spark=spark)\n",
    "df_test = dao_processed.load_processed_data(which_dataset=\"test\", id_data=id_data_build, spark=spark)\n",
    "\n",
    "print(f\"df_ttrain shape: {dflib.shape(df_ttrain)}\")\n",
    "print(f\"df_tvalid shape: {dflib.shape(df_tvalid)}\")\n",
    "print(f\"df_test shape: {dflib.shape(df_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8125cf",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee2cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import VectorAssembler #A feature transformer that merges multiple columns into a vector column.\n",
    "from pyspark.ml.feature import StringIndexer #A label indexer that maps a string column of labels to an ML column of label indices.\n",
    "from src.ml.transformers import UndersamplingTransformer, ProbaVectorToPrediction\n",
    "from src.ml.estimators import FillProbaEstimator\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, CrossValidatorModel, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from src.ml import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed03a1b",
   "metadata": {},
   "source": [
    "### Defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4219f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampling_transformer = UndersamplingTransformer(target_colname=\"target\")\n",
    "\n",
    "feature_assembler_transformer = VectorAssembler(inputCols=use_features, \n",
    "                                                outputCol=\"features\")\n",
    "\n",
    "target_indexer_transformer = StringIndexer(inputCol=\"target\", \n",
    "                                           outputCol=\"target_indexed\", \n",
    "                                           stringOrderType=\"alphabetDesc\").fit(df_ttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e27e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_train = PipelineModel(stages=[feature_assembler_transformer, \n",
    "                                       target_indexer_transformer])\n",
    "\n",
    "pipeline_test = PipelineModel(stages=[feature_assembler_transformer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bdea3a",
   "metadata": {},
   "source": [
    "### Applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9cdd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ttrain_na = dflib.filter_any_null(df_ttrain, subset=use_features)\n",
    "df_ttrain = DropNaTransformer(subset=use_features).transform(df_ttrain)\n",
    "\n",
    "df_tvalid_na = dflib.filter_any_null(df_tvalid, subset=use_features)\n",
    "df_tvalid = DropNaTransformer(subset=use_features).transform(df_tvalid)\n",
    "\n",
    "df_test_na = dflib.filter_any_null(df_test)\n",
    "df_test = DropNaTransformer().transform(df_test)\n",
    "\n",
    "print(f\"df_ttrain shape: {dflib.shape(df_ttrain)}\")\n",
    "print(f\"df_ttrain_na shape: {dflib.shape(df_ttrain_na)}\")\n",
    "print(f\"df_tvalid shape: {dflib.shape(df_tvalid)}\")\n",
    "print(f\"df_tvalid_na shape: {dflib.shape(df_tvalid_na)}\")\n",
    "print(f\"df_test shape: {dflib.shape(df_test)}\")\n",
    "print(f\"df_test_na shape: {dflib.shape(df_test_na)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5607883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ttrain = pipeline_train.transform(df_ttrain)\n",
    "df_tvalid = pipeline_train.transform(df_tvalid)\n",
    "df_test = pipeline_test.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3f6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_ttrain.union(df_tvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3070ec5b",
   "metadata": {},
   "source": [
    "# Choosing best strategy\n",
    "For dataset with <b>missing values</b> in features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a289ce8c",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c59e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_na_imputer(clf, df_train, df_valid, strategy='median'):\n",
    "    imputer = Imputer(strategy=strategy, inputCols=use_features, outputCols=use_features).fit(df_train)\n",
    "    df_valid_imputed = imputer.transform(df_valid)\n",
    "    df_valid_imputed = pipeline_test.transform(df_valid_imputed)\n",
    "    df_valid_imputed = target_indexer_transformer.transform(df_valid_imputed)\n",
    "    \n",
    "    preds_valid_imputed = clf.transform(df_valid_imputed)\n",
    "    \n",
    "    return preds_valid_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738bcdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_tvalid_na_median_imputed = predict_na_imputer(clf, df_ttrain, df_tvalid_na, strategy='median')\n",
    "preds_tvalid_na_mean_imputed = predict_na_imputer(clf, df_ttrain, df_tvalid_na, strategy='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc372235",
   "metadata": {},
   "source": [
    "#### Filling Prediction with Global Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0bb026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_na_filler(df_train, df_valid):\n",
    "    proba_filler = FillProbaEstimator(strategy=\"global_frequency\", labels=target_indexer_transformer.labels,\n",
    "                                      proba_vector_col=rfc.getProbabilityCol()).fit(df_train)\n",
    "\n",
    "    pred_indexer = ProbaVectorToPrediction(target_transformer=target_indexer_transformer, \n",
    "                                           prediction_col=\"prediction\")\n",
    "\n",
    "    df_valid_proba_filled = proba_filler.transform(df_valid)\n",
    "    preds_valid_filled = pred_indexer.transform(df_valid_proba_filled)\n",
    "    preds_valid_filled = target_indexer_transformer.transform(preds_valid_filled)\n",
    "    return preds_valid_filled\n",
    "\n",
    "preds_tvalid_na_filled = predict_na_filler(df_ttrain, df_tvalid_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd882b8",
   "metadata": {},
   "source": [
    "# Comparing missing values filling strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a7a47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f\"score_imputer (median): {preds_tvalid_na_median_imputed.count()}\")\n",
    "print(evaluator.evaluate(preds_tvalid_na_median_imputed))\n",
    "print()\n",
    "print(f\"score_imputer (mean): {preds_tvalid_na_mean_imputed.count()}\")\n",
    "print(evaluator.evaluate(preds_tvalid_na_mean_imputed))\n",
    "print()\n",
    "print(f\"score_filler: {preds_tvalid_na_filled.count()}\")\n",
    "print(evaluator.evaluate(preds_tvalid_na_filled))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
